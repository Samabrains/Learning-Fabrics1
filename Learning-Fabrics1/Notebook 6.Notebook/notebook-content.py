# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "49d11f17-17b2-4f96-941b-202ab7f1d585",
# META       "default_lakehouse_name": "Lakehouse1",
# META       "default_lakehouse_workspace_id": "c80302c8-0ac6-4eef-988c-fae517ab7b89",
# META       "known_lakehouses": [
# META         {
# META           "id": "49d11f17-17b2-4f96-941b-202ab7f1d585"
# META         }
# META       ]
# META     }
# META   }
# META }

# CELL ********************

df = spark.sql("SELECT * FROM Lakehouse1.dbo.dimension_city LIMIT 1000")
display(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Code generated by Data Wrangler for PySpark DataFrame

def clean_data(df):
    # Drop column: '__filepath__'
    df = df.drop('__filepath__')
    return df

df_clean = clean_data(df)
display(df_clean)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************


# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Code generated by Data Wrangler for PySpark DataFrame

from pyspark.sql import functions as F

def clean_data(df_clean):
    # Convert text to uppercase in columns: 'StateProvince', 'City' and 6 other columns
    df_clean = df_clean.withColumn('StateProvince', F.upper(F.col('StateProvince')))
    df_clean = df_clean.withColumn('City', F.upper(F.col('City')))
    df_clean = df_clean.withColumn('Country', F.upper(F.col('Country')))
    df_clean = df_clean.withColumn('Continent', F.upper(F.col('Continent')))
    df_clean = df_clean.withColumn('SalesTerritory', F.upper(F.col('SalesTerritory')))
    df_clean = df_clean.withColumn('Region', F.upper(F.col('Region')))
    df_clean = df_clean.withColumn('Subregion', F.upper(F.col('Subregion')))
    df_clean = df_clean.withColumn('Location', F.upper(F.col('Location')))
    return df_clean

df_clean_1 = clean_data(df_clean)
display(df_clean_1)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }
